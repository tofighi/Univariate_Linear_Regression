# -*- coding: utf-8 -*-
"""lab1_update_sherman.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5bj6HEFG6fnfIfSK2b-9uOrlRerHnB-

**Gradient Descent for Univariate Linear Regression**

Daniel Sherman

501034155

daniel.sherman@ryerson.ca

July 9, 2020
"""

#importing necessary libraries, etc.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression

#importing dataset

url = 'https://raw.githubusercontent.com/djsherm/Univariate_Linear_Regression/master/mark_data.csv'
data = pd.read_csv(url, error_bad_lines=False) #imported as pandas dataframe
print(data)
data = np.array(data) #convert to numpy array for manipulation

#plotting dataset
plt.scatter(data[:,0], data[:,1])
plt.title('Student Final Mark vs. Midterm Mark')
plt.xlabel('Midterm Mark')
plt.ylabel('Final Mark')

#store data in arrays of more meaningful names
mid = data[:,0]
fin = data[:,1]

#find average and standard deviation
mid_bar = np.mean(mid)
mid_std = np.std(mid)

fin_bar = np.mean(fin)
fin_std = np.std(fin)

#calculate Z scores
mid_prime = (mid - mid_bar)/mid_std
fin_prime = (fin - fin_bar)/fin_std

#make pandas dataframe to show nicely
df = pd.DataFrame({'Z Score of Midterm mark': mid_prime, 'Z Score of Final mark': fin_prime})
print(df)

"""Because I will have to run the main chunk of code with different cases, I'd like to make it a function"""

def univar_linregress(x, y, m_seed, b_seed, alpha, case):
  m = m_seed
  b = b_seed
  
  y_hat = m*x + b

  #plot dataset with initial regression line
  plt.scatter(x, y, label=case + ' Data')
  plt.plot(x, y_hat, color='black', label='Linear Regression')
  plt.title(str(case) + " Midterm Mark vs. " + str(case) +" Final Mark with Initial Regression")
  plt.xlabel(str(case)+' Midterm Mark')
  plt.ylabel(str(case)+' Final Mark')
  plt.legend()
  plt.show()

  #calculate error and update weights for 100 epochs
  error_update=[]
  fig_count = 1

  for i in range(2000):
    #calculate error and store for later
    err = np.sum(np.power((y - y_hat), 2))/len(y)
    error_update.append(err)

    #calculate partial derivatives
    di_m = (2/len(x))*np.sum(-x*(y - y_hat))
    di_b = (2/len(x))*np.sum(-(y - y_hat))

    #update weights
    m = m - alpha*di_m
    b = b - alpha*di_b

    y_hat = m*x + b #recalculate y_hat with new weights

    #check if 100 or 2000 epochs have passed
    if i ==  99 or i == 1999:
        plt.figure(fig_count)
        plt.subplots_adjust(bottom=2, top=4)
        plt.subplot(2,1,1)
        plt.scatter(x, y, label= str(case)+ ' Data')
        plt.plot(x, y_hat, color='black', label='Linear Rergression ('+str(i+1) + ' Epochs)')
        plt.xlabel(str(case) + ' Midterm Mark')
        plt.ylabel(str(case) + ' Final Mark')
        plt.legend()
        plt.title(str(case) + ' Midterm Mark vs. ' + str(case) + ' Final Mark after ' + str(i+1) + ' Epochs')

        plt.subplot(2,1,2)
        plt.plot(range(len(error_update)), error_update)
        plt.title('Error Over ' + str(i+1) + ' Epochs')
        plt.xlabel('Epochs')
        plt.ylabel('Error (' + 'Learning Rate = ' + str(alpha)+')')
        fig_count = fig_count + 1

  print(m,b)

univar_linregress(mid_prime, fin_prime, -0.5, 0, 0.0001, 'Standardized')

univar_linregress(mid, fin, -0.5, 0, 0.0001, 'Raw')

univar_linregress(mid_prime, fin_prime, -0.5, 0, 0.1, 'Standardized')

univar_linregress(mid, fin, -0.5, 0, 0.1, 'Raw') #WHY AM I GETTING RUNTIME WARNINGS ONLY WITH THIS CASE??

def linear_verif(x, y, case):
  x = x.reshape(-1,1)
  y = y.reshape(-1,1)
  reg = LinearRegression()
  x_pred = np.linspace(min(x), max(x)).reshape(-1,1)
  reg.fit(x, y)
  y_hat = reg.predict(x_pred)

  #R^2 score
  print(reg.score(x, y))
  print(reg.coef_, reg.intercept_)

  plt.scatter(x,y, label=str(case)+' Data')
  plt.plot(x_pred, y_hat, color='black', label='sklearn Regression')
  plt.legend()
  plt.xlabel(str(case)+' Midterm Mark')
  plt.ylabel(str(case)+' Final Mark')
  plt.title(str(case)+' Midterm Mark vs. '+str(case)+' Final Mark with sklearn Regression')

linear_verif(mid_prime, fin_prime, 'Standardized')

linear_verif(mid, fin, 'Raw')